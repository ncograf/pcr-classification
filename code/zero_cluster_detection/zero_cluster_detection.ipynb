{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_lib\n",
    "import plot_lib\n",
    "import decision_lib\n",
    "import validation_lib\n",
    "import transform_lib\n",
    "from icecream import ic\n",
    "import stats_lib \n",
    "\n",
    "np.random.seed(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "-- The following 4 groups were found\n",
      "-- They contain 40 datasets\n",
      "-- The first printed entity is the key to the returned dictionary\n",
      "-----------------------------------\n",
      "Group: ../../Data/6P-positive-dilution-series-2-labelled/droplet-level-data/RawData\n",
      "po-di-se-2-A4, files: 13                po-di-se-2-C4, files: 13                po-di-se-2-A1, files: 13\n",
      "po-di-se-2-B1, files: 13                po-di-se-2-D1, files: 13                po-di-se-2-B4, files: 13\n",
      "po-di-se-2-C1, files: 13                po-di-se-2-D4, files: 13                \n",
      "-----------------------------------\n",
      "Group: ../../Data/6P-positive-dilution-series-1-labelled/droplet-level-data/RawData\n",
      "po-di-se-1-D4, files: 13                po-di-se-1-A4, files: 13                po-di-se-1-A1, files: 13\n",
      "po-di-se-1-D1, files: 13                po-di-se-1-B1, files: 13                po-di-se-1-C1, files: 13\n",
      "po-di-se-1-B4, files: 13                po-di-se-1-C4, files: 13                \n",
      "-----------------------------------\n",
      "Group: ../../Data/6P-positive-dilution-series-labelled/droplet-level-data/RawData\n",
      "po-di-se-B8, files: 13                  po-di-se-A8, files: 13                  po-di-se-C8, files: 13\n",
      "po-di-se-D8, files: 13                                                          \n",
      "-----------------------------------\n",
      "Group: ../../Data/6P-wastewater-samples-labelled/droplet-level-data/RawData\n",
      "wa-sa-A2, files: 13                     wa-sa-B4, files: 13                     wa-sa-C5, files: 13\n",
      "wa-sa-C4, files: 13                     wa-sa-B3, files: 13                     wa-sa-B2, files: 13\n",
      "wa-sa-A5, files: 13                     wa-sa-A3, files: 13                     wa-sa-C2, files: 13\n",
      "wa-sa-C3, files: 13                     wa-sa-D3, files: 13                     wa-sa-D4, files: 13\n",
      "wa-sa-B1, files: 13                     wa-sa-A4, files: 13                     wa-sa-A1, files: 13\n",
      "wa-sa-D2, files: 13                     wa-sa-D5, files: 13                     wa-sa-C1, files: 13\n",
      "wa-sa-B5, files: 13                     wa-sa-D1, files: 13                     \n",
      "-----------------------------------\n",
      "['IAV-M_POS', 'IAV-M_NEG', 'IBV-M_POS', 'IBV-M_NEG', 'MHV_POS', 'MHV_NEG', 'RSV-N_POS', 'RSV-N_NEG', 'SARS-N1_POS', 'SARS-N1_NEG', 'SARS-N2_POS', 'SARS-N2_NEG']\n"
     ]
    }
   ],
   "source": [
    "# print available data summary\n",
    "data_dict = data_lib.explore_datasets(datafolder=\"../../Data\",verbose=True)\n",
    "print(data_lib.LABELS_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples for negative control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all discovered datasets\n",
    "file_list = data_dict.keys()\n",
    "\n",
    "# mark negative contorls\n",
    "negative_control_list =[\n",
    "                        \"wa-sa-D3\",\n",
    "                        \"wa-sa-D5\",\n",
    "                        \"po-di-se-1-D1\",\n",
    "                        \"po-di-se-1-D4\",\n",
    "                        \"po-di-se-2-D1\", \n",
    "                        \"po-di-se-2-D4\",\n",
    "                        \"po-di-se-D8\",\n",
    "                       ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.mean(np.concatenate(pos_list)): 1.546217853889672\n",
      "ic| np.std(np.concatenate(pos_list)): 1.2634362717927208\n",
      "ic| np.mean(np.concatenate(neg_list)): 0.07794832879658467\n",
      "ic| np.std(np.concatenate(neg_list)): 0.08847322513795011\n",
      "ic| np.mean(np.concatenate(neg_control_list)): 0.03647890062131418\n",
      "ic| np.std(np.concatenate(neg_control_list)): 0.034002712919506496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.034002712919506496"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix clustering algorithm\n",
    "prediction_axis = ['SARS-N2_POS','SARS-N1_POS','IBV-M_POS','RSV-N_POS','IAV-M_POS','MHV_POS']\n",
    "neg_list = []\n",
    "pos_list = []\n",
    "neg_control_list = []\n",
    "for file in file_list:\n",
    "    df = data_lib.load_dataset(prediction_axis,  [file], datafolder=\"../../Data\")\n",
    "    np_data = df.to_numpy()\n",
    "    np_chan = np_data[:,:6]\n",
    "    np_labels = np_data[:,6:]\n",
    "    n = np_data.shape[0]\n",
    "    active = ~(np.sum(np_labels, axis=0) / n == 0)\n",
    "    certainty, _, statistic = decision_lib.get_negative_dimensions(np_chan, 0.001)\n",
    "    statistic = statistic / n\n",
    "    exceptions = {\n",
    "        \"wa-sa-B3\" : np.array([True, True, True, False, False, True], dtype=bool),\n",
    "        \"wa-sa-A2\" : np.array([True, True, True, False, False, True], dtype=bool),\n",
    "        \"wa-sa-B2\" : np.array([True, True, True, False, False, True], dtype=bool),\n",
    "        \"wa-sa-A3\" : np.array([True, True, True, False, False, True], dtype=bool),\n",
    "        \"wa-sa-B1\" : np.array([True, True, True, False, False, True], dtype=bool),\n",
    "        \"wa-sa-A1\" : np.array([True, True, True, False, False, True], dtype=bool),\n",
    "\n",
    "        \"wa-sa-C2\" : np.array([True, True, True, False, False, False], dtype=bool),\n",
    "        \"wa-sa-D1\" : np.array([True, True, True, False, False, False], dtype=bool),\n",
    "        \"wa-sa-D2\" : np.array([True, True, True, False, False, False], dtype=bool),\n",
    "        \"wa-sa-C1\" : np.array([True, True, True, False, False, False], dtype=bool),\n",
    "\n",
    "        \"wa-sa-B4\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"wa-sa-C4\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"wa-sa-D3\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"wa-sa-D4\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"wa-sa-D5\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"wa-sa-A4\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"wa-sa-B5\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \n",
    "        \"po-di-se-1-D1\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "        \"po-di-se-D8\" : np.array([False, False,False, False, False, False], dtype=bool),\n",
    "                  }\n",
    "    if file in exceptions.keys():\n",
    "        active = exceptions[file]\n",
    "    if file in negative_control_list:\n",
    "        neg_control_list.append(statistic)\n",
    "    neg_list.append(statistic[~active])\n",
    "    pos_list.append(statistic[active])\n",
    "    if np.any(active) and np.any(~active) and (not file in exceptions.keys()):\n",
    "        ic(file, certainty, statistic, active)\n",
    "\n",
    "    #df_data_points = pd.DataFrame(data=decision.X_transformed, columns=prediction_axis) \n",
    "ic(np.mean(np.concatenate(pos_list)))\n",
    "ic(np.std(np.concatenate(pos_list)))\n",
    "ic(np.mean(np.concatenate(neg_list)))\n",
    "ic(np.std(np.concatenate(neg_list)))\n",
    "ic(np.mean(np.concatenate(neg_control_list)))\n",
    "ic(np.std(np.concatenate(neg_control_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
